{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using Scrapy To Scrape For Specific Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a notebook that demonstrates the use of the Scrapy python library to extract specific information from a website and then organizes said information into a pandas dataframe, displayed as a table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Included is a page-turning web-crawler so that we can acquire all the relevant data from the website."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8vaW0eIeq4i"
      },
      "outputs": [],
      "source": [
        "!pip install scrapy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFMjvERQetNm"
      },
      "outputs": [],
      "source": [
        "import scrapy\n",
        "from scrapy.crawler import CrawlerProcess\n",
        "\n",
        "class QuotesSpider(scrapy.Spider):\n",
        "    name = \"quotes\"\n",
        "    start_urls = ['http://quotes.toscrape.com']\n",
        "\n",
        "    def parse(self, response):\n",
        "        for quote in response.css('div.quote'):\n",
        "            yield {\n",
        "                'text': quote.css('span.text::text').get(),\n",
        "                'author': quote.css('span small::text').get(),\n",
        "                'tags': quote.css('div.tags a.tag::text').getall(),\n",
        "            }\n",
        "        next_page = response.css('li.next a::attr(href)').get()\n",
        "        if next_page is not None:\n",
        "            yield response.follow(next_page, self.parse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gY6DmsYpet5k"
      },
      "outputs": [],
      "source": [
        "process = CrawlerProcess({\n",
        "    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)',\n",
        "    'FEED_FORMAT': 'json',\n",
        "    'FEED_URI': 'quotes.json'\n",
        "})\n",
        "\n",
        "process.crawl(QuotesSpider)\n",
        "process.start()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8EI0eCCeuD6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_json('quotes.json')\n",
        "data.head()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.2 ('scraperenv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "9e434f975329fc328febc6fa12b9249bc7786c502c3865202e731a796ee07a46"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
